---



layout: post

title: "인공지능 및 기계학습 개론 3강 요약"

author: "hyeju.kim"

categories: ML

tags:  네이버

image: 
---

## 인공지능 및 기계학습 개론 . 3강 Naive Bayes Classifier



[edwith 인공지능 및 기계학습개론 강의](https://www.edwith.org/machinelearning1_17/lecture/10585/)를 참고하여 만들어진 포스트입니다.



- [Optimal Classification](#1. Optimal Classification)
- [Decision Tree](#2. Decision Tree)
- [Linear Regression](#3. Linear Regression)
- [Entropy in Machine Learning 정의하기](#Entropy 에 대해 간략히 정의해보자.)



### 1. Optimal Classification

- Optimal predictor of Bayes classifier

$f^* = argmin_f P(\hat{Y} != Y)$

두 개의 클래스일 경우:

 $f^*(x) = argmax_{Y=y} P(Y=y|X=x)$

$= argmax_{Y=y}P(X=x|Y=y)P(Y=y)$

P(X=x|Y=y): Class Conditional Density = Likelihood, P(Y=y) = Class Prior

주어진 x값에서 제대로 class를 판단하게끔 (극단적으로) 판단하기.(곡선형태)



- X변수들이 많아진다면?

  변수들끼리의 interaction이 생긴다. <u>이 interaction이 없다고 가정하는 것이 naive bayes classifier</u>



## 2. Naive Bayes Classifier

![image](https://user-images.githubusercontent.com/32008883/42733769-3f45445c-8872-11e8-9ece-5c1de7d9d927.png)

다음과 같은 경우 

P(X=x|Y=y) 는 x변수가 너무 많아 구하기 힘들다. 

즉 그래서 다음과 같은 가정을 사용한게 Naive Bayes Classifier이다.

![image](https://user-images.githubusercontent.com/32008883/42733789-bd3b6ca6-8872-11e8-8acb-ec7a2ae032f1.png)

- conditional independece

관측치(Y)가 알려지지 않았을 때는 다른 X2변수가 X1에 영향 미칠 수 있다. 그러나 관측치(Y)가 알려졌을 때는 다른 X2변수가 X1에 영향 미치지 않는다는 것이 Conditional Independence

- naive bayes classifier function 정리

![image](https://user-images.githubusercontent.com/32008883/42733936-cf089c9e-8875-11e8-82aa-6a0e9e1b8ff8.png)





- 한계 1 : Naive Asssumption

- 한계 2: incorrect Probability Estimations

  관측치가 별로 없을 경우(insufficient data) 제대로 못 구할 수 있다. MLE -> MAP(prior사용해서라도)



## 3. 예시: Sentimental Analysis using Naive Bayes Classifier

![image](https://user-images.githubusercontent.com/32008883/42733997-fc043450-8876-11e8-9ffb-de747cae0ff8.png)



log 사용하는 이유: 0에 가까우면 곱하기를 많이하면 0. 000xxx 형태로 되는데, 이걸 컴퓨터에서는 0으로 인식하기 때문에 log씌어줌.



## 4. Naive Bayes Classifier 정의// sentimental analysis  간단한 코드 찾아보기

